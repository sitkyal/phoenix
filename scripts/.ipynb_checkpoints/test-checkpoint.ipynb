{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fpre_process(fname):\n",
    "    # Hot encoding for all categorical columns\n",
    "    # Impute values for nulls in categorical and numerical columns\n",
    "\n",
    "    # 1. Get the selected labels and features - Done\n",
    "    # 2. Determine the cat / numerical in features - Done\n",
    "    # 3. Determine columns with Nulls - Done\n",
    "    # 4. Determine most frequent in Cat - Done\n",
    "    # 5. Impute cat column values with most frequent - Done\n",
    "    # 6. Detemine mean / average for Num - Done \n",
    "    # 7. Impute num column values with mean - Done\n",
    "    # 8. Hot Encode - Done\n",
    "    # 9. Standardize \n",
    "    # 10. Return X and y\n",
    "\n",
    "    # for testing - Replace this code with extracting from label_features.py\n",
    "    label = ['Survived']\n",
    "    features = ['Pclass', 'Sex', 'Age', 'Embarked', 'Cabin']\n",
    "    \n",
    "    from base_script_eda import fload_csv\n",
    "    \n",
    "    df, size = fload_csv(fname)\n",
    "\n",
    "    # calculate the numerical and cat columns\n",
    "\n",
    "    df_bkp = df[features]\n",
    "    cols = list(df[features].columns)\n",
    "    num_cols = list(df[features]._get_numeric_data().columns)\n",
    "    cat_cols = list(set(cols) - set(num_cols))\n",
    "    \n",
    "    \n",
    "    # Determine columns with Null values and Replace NAs\n",
    "    \n",
    "    null_num_cols = df[num_cols].columns[df[num_cols].isnull().any()].tolist()\n",
    "    null_cat_cols = df[cat_cols].columns[df[cat_cols].isnull().any()].tolist()\n",
    "    #print null_num_cols, null_cat_cols\n",
    "    \n",
    "    # For numerical columns\n",
    "    \n",
    "    for col in null_num_cols:\n",
    "        #print \"Before \" + str(df[col].isnull().sum())\n",
    "        #df[col].replace(np.NaN, df[col].mean(), inplace=True)\n",
    "        df[col].fillna(df[col].mean(), inplace=True)\n",
    "        #print \"After \" + str(df[col].isnull().sum())\n",
    "    \n",
    "    # For categorical columns impute and hot encode\n",
    "    \n",
    "    for col in null_cat_cols:\n",
    "        \n",
    "        # impute missing values\n",
    "        \n",
    "        #print \"Before \" + str(df[col].isnull().sum())\n",
    "        #df[col].replace(np.NaN, df[col].value_counts().max(), inplace=True)\n",
    "        df[col].fillna(df[col].value_counts().max(), inplace=True)\n",
    "        #print \"After \" +  str(df[col].isnull().sum())\n",
    "        #print \" Successfully Completed Null Imputation: \" + str(col)\n",
    "    \n",
    "    for col in null_cat_cols:\n",
    "        # Hot Encode \n",
    "        \n",
    "        #print \"Before encode: \" + str(df.shape)\n",
    "        df = pd.concat([df, pd.get_dummies(df[col])], axis=1)\n",
    "        #print \" Successfully Completed Hot Encode: \" + str(col)\n",
    "        #print \"After encode: \" + str(df.shape)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.csv successfully loaded\n"
     ]
    }
   ],
   "source": [
    "fpre_process('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# define example\n",
    "data = ['cold', 'cold', 'warm', 'cold', 'hot', 'hot', 'warm', 'cold', 'warm', 'hot']\n",
    "values = array(data)\n",
    "print(values)\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "print(integer_encoded)\n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "print(onehot_encoded)\n",
    "# invert first example\n",
    "inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0, :])])\n",
    "print(inverted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['IsAlone'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.show_versions(as_json=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
