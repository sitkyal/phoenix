{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fpre_process(fname):\n",
    "    # Hot encoding for all categorical columns\n",
    "    # Impute values for nulls in categorical and numerical columns\n",
    "\n",
    "    # 1. Get the selected labels and features - Done\n",
    "    # 2. Determine the cat / numerical in features - Done\n",
    "    # 3. Determine columns with Nulls - Done\n",
    "    # 4. Determine most frequent in Cat - Done\n",
    "    # 5. Impute cat column values with most frequent - Done\n",
    "    # 6. Detemine mean / average for Num - Done\n",
    "    # 7. Impute num column values with mean - Done\n",
    "    # 8. Hot Encode - Done\n",
    "    # 9. Standardize - TBD\n",
    "    # 10. Return X and y - Done\n",
    "    # 11. Include label in the pre-process\n",
    "\n",
    "    # Get the labels and features selected\n",
    "\n",
    "    from label_features import flabel_features\n",
    "    olabel, ofeatures = flabel_features() # uncomment when testing is done\n",
    "\n",
    "\n",
    "    def load_process():\n",
    "        from load import fload_csv\n",
    "        df, size = fload_csv(fname)\n",
    "    # Store in temp dataframe\n",
    "        tdf = df[ofeatures].copy()\n",
    "        ldf = df[olabel].copy()\n",
    "        return tdf, ldf\n",
    "\n",
    "    def null_process(tdf, ldf):\n",
    "\n",
    "    # calculate the numerical and cat columns\n",
    "\n",
    "        cols = list(tdf.columns)\n",
    "        num_cols = list(tdf._get_numeric_data().columns)\n",
    "        cat_cols = list(set(cols) - set(num_cols))\n",
    "\n",
    "    # Determine columns with Null values and Replace NAs\n",
    "\n",
    "        null_num_cols = tdf[num_cols].columns[tdf[num_cols].isnull().any()\n",
    "                                          ].tolist()\n",
    "        null_cat_cols = tdf[cat_cols].columns[tdf[cat_cols].isnull().any()\n",
    "                                          ].tolist()\n",
    "\n",
    "    # For numerical columns\n",
    "\n",
    "        for col in null_num_cols:\n",
    "            tdf[col].fillna(tdf[col].mean(), inplace=True)\n",
    "\n",
    "    # For categorical columns impute and hot encode\n",
    "\n",
    "        for col in null_cat_cols:\n",
    "        # impute missing values\n",
    "            tdf[col].fillna(tdf[col].value_counts().max(), inplace=True)\n",
    "\n",
    "        for col in cat_cols:\n",
    "            # Hot One Encode\n",
    "            tdf = pd.concat([tdf, pd.get_dummies(tdf[col])], axis=1)\n",
    "\n",
    "        tdf.drop(cat_cols, axis=1, inplace=True)\n",
    "        return tdf, ldf\n",
    "\n",
    "\n",
    "    tdf, ldf = load_process()\n",
    "    tdf, ldf = null_process(tdf, ldf)\n",
    "\n",
    "    # Extract X and y\n",
    "    y = ldf.as_matrix().astype(np.float)\n",
    "    X = tdf.as_matrix().astype(np.float)\n",
    "\n",
    "    # reshape for cross validation - sheez!\n",
    "    c, r = y.shape\n",
    "    y = y.reshape(c,)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data successfully loaded\n"
     ]
    }
   ],
   "source": [
    "X, y = fpre_process('train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, StratifiedKFold\n",
    "from sklearn import metrics\n",
    "def ds(X, y):\n",
    "    cm = DecisionTreeClassifier()\n",
    "    cv = StratifiedKFold(n_splits=20)\n",
    "    ypred = cross_val_predict(cm, X,y, cv=cv, n_jobs=-1)\n",
    "    yscore = cross_val_predict(cm, X,y, cv=cv, n_jobs=-1, method='predict_proba')\n",
    "    score = metrics.accuracy_score(y, ypred)\n",
    "    return score, ypred, yscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.81593714927\n"
     ]
    }
   ],
   "source": [
    "score, ypred, yscore = ds(X,y)\n",
    "print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "0.78\n",
      "0.833622183709 0.81593714927 0.18406285073 0.876138433515 0.216560509554 0.854351687389 0.814297504351 6.35736666823 0.606152748139\n",
      "0.797718339565\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "cmatrix = metrics.confusion_matrix(y, ypred)\n",
    "print type(cmatrix)\n",
    "TP = cmatrix[0,0]\n",
    "TN = cmatrix[1,1]\n",
    "FP = cmatrix[0,1]\n",
    "FN = cmatrix[1,0]\n",
    "\n",
    "Specificity = ((TN*1.0)/(TN+FP))\n",
    "Sensitivity = ((TP*1.0)/(TP+FN))\n",
    "Accuracy = ((TP+TN)*1.0)/(TN+TP+FP+FN)\n",
    "Error_Rate = ((FP+FN)*1.0)/(TN+TP+FP+FN)\n",
    "Precision = ((TP*1.0)/(TP+FP))\n",
    "FPR = ((FP*1.0)/(TN+FP))\n",
    "f1score = (2*Precision*Sensitivity) / (Precision + Sensitivity)\n",
    "skf1score = metrics.f1_score(y, ypred, average='weighted')\n",
    "neglogloss = metrics.log_loss(y, ypred, eps=1e-15, normalize=True)\n",
    "mcc = metrics.matthews_corrcoef(y, ypred)\n",
    "\n",
    "print '{:03.2f}'.format(Specificity)\n",
    "print Sensitivity, Accuracy, Error_Rate, Precision, FPR, f1score, skf1score, neglogloss, mcc\n",
    "\n",
    "# Confusion Matrix Related Metrics\n",
    "\n",
    "\n",
    "Avg_Precision_Score = metrics.average_precision_score(y, yscore[:,1], average='macro')\n",
    "\n",
    "# ROC Curve\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y, yscore[:,1])\n",
    "auc_score = metrics.roc_auc_score(y, yscore[:,1])\n",
    "print auc_score\n",
    "# Precision Curve\n",
    "\n",
    "precision, recall, thresholds = metrics.precision_recall_curve(y, yscore[:,1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dict Test\n",
    "def f(i):\n",
    "    return {\n",
    "        'decision_tree': decision_tree,\n",
    "        'knn': knn\n",
    "    }.get(i, decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "\n",
    "# Import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Binarize the output\n",
    "y = label_binarize(y, classes=[0, 1, 2])\n",
    "n_classes = y.shape[1]\n",
    "\n",
    "# Add noisy features to make the problem harder\n",
    "random_state = np.random.RandomState(0)\n",
    "n_samples, n_features = X.shape\n",
    "X = np.c_[X, random_state.randn(n_samples, 200 * n_features)]\n",
    "\n",
    "# shuffle and split training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5,\n",
    "                                                    random_state=0)\n",
    "\n",
    "# Learn to predict each class against the other\n",
    "classifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True,\n",
    "                                 random_state=random_state))\n",
    "y_score = classifier.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr[2], tpr[2], color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = accuracy_score(ytest, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84090909090909094"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction with RFE\n",
    "from pandas import read_csv\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# load data\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(url, names=names)\n",
    "print dataframe.head(10)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "# feature extraction\n",
    "model = LogisticRegression()\n",
    "rfe = RFE(model, 3)\n",
    "fit = rfe.fit(X, Y)\n",
    "print(\"Num Features: %d\") % fit.n_features_\n",
    "print(\"Selected Features: %s\") % fit.support_\n",
    "print(\"Feature Ranking: %s\") % fit.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# define example\n",
    "data = ['cold', 'cold', 'warm', 'cold', 'hot', 'hot', 'warm', 'cold', 'warm', 'hot']\n",
    "values = array(data)\n",
    "print(values)\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "print(integer_encoded)\n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "print(onehot_encoded)\n",
    "# invert first example\n",
    "inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0, :])])\n",
    "print(inverted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = [[1,2,3],[4,5,6],[7,8,9]]\n",
    "f1 = [1, 2, 3]\n",
    "t1 = [3, 4, 5]\n",
    "f2 = [6, 7, 8]\n",
    "t2 = [10, 11, 12]\n",
    "d = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1 = ['m1' for i in f1]\n",
    "st2 = ['m2' for i in f2]\n",
    "d.append(st1)\n",
    "d.append(f1)\n",
    "d.append(t1)\n",
    "dn = np.array(d).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['m1', '1', '3'],\n",
       "       ['m1', '2', '4'],\n",
       "       ['m1', '3', '5']], \n",
       "      dtype='|S2')"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = []\n",
    "d.append(st2)\n",
    "d.append(f2)\n",
    "d.append(t2)\n",
    "dn1 = np.array(d).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['m2', '6', '10'],\n",
       "       ['m2', '7', '11'],\n",
       "       ['m2', '8', '12']], \n",
       "      dtype='|S2')"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dn1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dn = np.append(dn, dn1, axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['m1', '1', '3'],\n",
       "       ['m1', '2', '4'],\n",
       "       ['m1', '3', '5'],\n",
       "       ['m2', '6', '10'],\n",
       "       ['m2', '7', '11'],\n",
       "       ['m2', '8', '12']], \n",
       "      dtype='|S2')"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(dnx,columns=['model_name','FPR', 'TPR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "gh = np.zeros(shape=(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>FPR</th>\n",
       "      <th>TPR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model_name, FPR, TPR]\n",
       "Index: []"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
